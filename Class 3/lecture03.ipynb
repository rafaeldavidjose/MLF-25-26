{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304b0c06",
   "metadata": {},
   "source": [
    "# Machine Learning Fundamentals - Lecture 03\n",
    "\n",
    "This is the Jupyter notebook for Lecture 03 of the Machine Learning Fundamentals\n",
    "course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99f40c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries using the commonly use short names (pd, sns, ...)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# The Path object from pathlib allows us to easily build paths in an\n",
    "# OS-independent fashion\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the required scikit-learn classes and functions\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Set a nicer style for Seaborn plots\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b4f293",
   "metadata": {},
   "source": [
    "## Part 1: load and clean the Pok√©mon dataset\n",
    "\n",
    "Here we just repeat the steps already done in the previous lectures, but in a\n",
    "more succint way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "761fb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (note the use of the Path object)\n",
    "df = pd.read_csv(Path(\"Pokemon.csv\"))\n",
    "\n",
    "# It's not good practice to have column names with spaces and other non-standard\n",
    "# characters, so let's fix this by renaming the columns to standard names\n",
    "df.rename(columns={\n",
    "    \"Type 1\" : \"Type1\",\n",
    "    \"Type 2\" : \"Type2\",\n",
    "    \"Sp. Atk\" : \"SpAtk\",\n",
    "    \"Sp. Def\" : \"SpDef\",\n",
    "}, inplace=True)\n",
    "\n",
    "# Replace missing values in the \"Type2\" column with the string \"None\"\n",
    "df[\"Type2\"] = df[\"Type2\"].fillna(\"None\")\n",
    "\n",
    "# Since primary and secondary types are essentially categories (and not just\n",
    "# strings / objects), we can convert these columns to the category type\n",
    "df[\"Type1\"] = df[\"Type1\"].astype(\"category\")\n",
    "df[\"Type2\"] = df[\"Type2\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07466c93",
   "metadata": {},
   "source": [
    "Before we proceed to the interesting part, we'll perform our data scaling and\n",
    "train/test data splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41193ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use all features except the Total, which can be considered redundant\n",
    "# since it's the total of the other features\n",
    "features = [\"HP\", \"Attack\", \"Defense\", \"SpAtk\", \"SpDef\", \"Speed\"]\n",
    "\n",
    "# Get only the specified features\n",
    "df_X = df[features]\n",
    "\n",
    "# Standardize them\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df_X)\n",
    "\n",
    "# Our labels will be the legendary status\n",
    "y_leg = df[\"Legendary\"].to_numpy()\n",
    "\n",
    "# Let's split our data into training (80%) and test (20%) sets\n",
    "# Change the random_state parameter do split data in different ways\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_leg, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648147a5",
   "metadata": {},
   "source": [
    "## Part 2: Implement our own $k$-Nearest Neighbors classifier and regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb6ed975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this variable to change k for all the tests in this section\n",
    "k_for_all = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32f93608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(X_Train, y_train, X_test, k=5):\n",
    "    dists = euclidean_distances(X_test, X_Train)\n",
    "    \n",
    "    idx_k_min = np.argpartition(dists, k, axis=1)[:, :k]\n",
    "\n",
    "    labels_k_min = y_train[idx_k_min]\n",
    "    \n",
    "    num_pred = X_test.shape[0]\n",
    "    \n",
    "    maj_labels = np.zeros(num_pred, dtype=y_train.dtype)\n",
    "\n",
    "    for i, row in enumerate(labels_k_min):\n",
    "        \n",
    "       values, counts = np.unique(row, return_counts=True)\n",
    "       \n",
    "       i_max = np.argmax(counts)\n",
    "       \n",
    "       maj_labels[i] = values[i_max]\n",
    "       \n",
    "    return maj_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8c584aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (our kNN): 0.9250\n",
      "Accuracy (sklearn kNN): 0.9250\n"
     ]
    }
   ],
   "source": [
    "y_pred_ours = knn_classify(X_train, y_train, X_test, k=k_for_all)\n",
    "accuracy_ours = accuracy_score(y_test, y_pred_ours)\n",
    "\n",
    "knnClf = KNeighborsClassifier(n_neighbors=k_for_all)\n",
    "knnClf.fit(X_train, y_train)\n",
    "y_pred_knn = knnClf.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"Accuracy (our kNN): {accuracy_ours:.4f}\")\n",
    "print(f\"Accuracy (sklearn kNN): {accuracy_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d4c4ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_ours, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "04552fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_regression(X_Train, y_train, X_test, k=5):\n",
    "    dists = euclidean_distances(X_test, X_Train)\n",
    "    \n",
    "    idx_k_min = np.argpartition(dists, k, axis=1)[:, :k]\n",
    "\n",
    "    return y_train[idx_k_min].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b2a59891",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = df[\"Total\"].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_total, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "932cf851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.832500000000005"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_regr_ours = knn_regression(X_train, y_train, X_test, k=k_for_all)\n",
    "mean_absolute_error(y_test, y_regr_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "19018474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031841346483808264"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, y_regr_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e3319ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.832500000000005"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnRegr = KNeighborsRegressor()\n",
    "knnRegr.fit(X_train, y_train)\n",
    "y_regr_knn = knnRegr.predict(X_test)\n",
    "mean_absolute_error(y_test, y_regr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "add53c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031841346483808264"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_percentage_error(y_test, y_regr_ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_regr_ours, y_regr_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
